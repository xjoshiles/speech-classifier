"""
Split unified audio manifests into train, validation, and test sets using multiple strategies.

This script takes as input the unified manifest files generated by `generate_unified_manifests.py` and
produces stratified data splits for model training and evaluation. It supports multiple feature types
(e.g., raw, MFCC, spectrogram_2d, wav2vec) and three flexible split strategies, each
designed for different evaluation scenarios.

This is the **final step of the preprocessing pipeline**, and must be run after:
    - Speaker metadata preparation (`vctk_update_speaker_info.py`)
    - Audio resampling and synthesis (real + synthetic)
    - Feature extraction (via `extract_features.py`)
    - Unified manifest generation (`generate_unified_manifests.py`)

Supported split strategies:
    - `"speaker"`: Ensures disjoint speakers across train/val/test
    - `"utterance"`: Ensures disjoint (speaker, transcript) pairs across splits
    - `"tts_system"`: Ensures disjoint combinations of speakers and TTS systems, supporting strong generalisation

The script also filters the dataset to retain:
    - Only speakers present in **all** TTS systems and in the real data
    - Only (speaker_id, transcript_id) pairs that include one real and one synthetic utterance per TTS system

Outputs:
    - One split manifest per feature type and strategy:
        `split_{strategy}_{feature}.tsv` (e.g., `split_utterance_mfcc.tsv`)
      Stored in: `data/manifests/`

Each manifest contains labeled entries for both real and synthetic utterances, and includes fields for:
    - File path
    - Label ("real" or "synthetic")
    - Speaker ID
    - Gender
    - Transcript ID
    - TTS system (if synthetic, else 'original')
    - Feature type
    - Split assignment (`train`, `val`, or `test`)
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split

# Configuration
HERE = Path(__file__).parent
MANIFEST_DIR     = HERE.parent / "data/manifests"
FEATURE_TYPES    = ["raw", "mfcc", "spectrogram_2d", "wav2vec"]
SPLIT_STRATEGIES = ["tts_system", "speaker", "utterance"]
RANDOM_STATE     = 42  # for reproducibility


def split_manifest(manifest_path, strategy="tts_system", random_state=42):
    """
    Filters and splits a unified manifest of real and synthetic audio into train/val/test sets.
    
    This function supports three splitting strategies:
    
    - "speaker": 
        Ensures speakers are disjoint across splits. Each speaker appears in only one of 
        train/val/test. All real and synthetic utterances for a speaker are assigned to the same split.
    
    - "utterance":
        Ensures (speaker_id, transcript_id) pairs are disjoint across splits. This allows for 
        evaluating whether a model generalises to unseen utterances from known speakers and systems.
    
    - "tts_system": 
        Ensures both speakers and synthetic TTS systems are disjoint across splits. 
        Real utterances are split by speaker; synthetic samples are only included if their 
        speaker and TTS system are assigned to the same split. This supports strong generalisation 
        evaluation to unseen voices and unseen synthesis methods.
    
    Additionally, the manifest is filtered to:
    - Include only speakers present in all TTS systems and the original data
    - Retain only (speaker_id, transcript_id) pairs with exactly 1 real and 1 sample per TTS system
    
    Args:
        manifest_path (str or Path): Path to the fully matched manifest TSV.
        strategy (str): One of "speaker", "utterance", or "tts_system".
        random_state (int): Random seed for reproducibility.
    
    Returns:
        dict: { 'train': DataFrame, 'val': DataFrame, 'test': DataFrame }
    """
    assert strategy in {"speaker", "utterance", "tts_system"}, "Invalid strategy"
    df = pd.read_csv(manifest_path, sep='\t', dtype={"transcript_id": str})
    
    
    # === Step 1: Keep only speakers present in all TTS systems + real ===
    
    # Split the data into real and synthetic parts, and list available TTS systems
    real_df = df[df["tts_system"] == "original"]
    synth_df = df[df["tts_system"] != "original"]
    tts_systems = synth_df["tts_system"].unique().tolist()
    
    # Create a dictionary mapping each TTS system to the set of speakers it covers
    speakers_by_system = {
        system: set(synth_df[synth_df["tts_system"] == system]["speaker_id"].unique())
        for system in tts_systems
    }
    
    # Find speaker_ids that are present in all TTS systems and in the real data
    real_speakers = set(real_df["speaker_id"].unique())
    common_speakers = real_speakers.intersection(*speakers_by_system.values())
    
    # Filter entire dataset to keep only common speakers
    df = df[df["speaker_id"].isin(common_speakers)]
    real_df = df[df["tts_system"] == "original"]
    synth_df = df[df["tts_system"] != "original"]
    
    
    # === Step 2: Keep only (speaker, transcript) pairs with 1 real + all TTS systems ===
    
    # Get (speaker_id, transcript_id) pairs that have exactly one sample per TTS system
    synth_grouped = synth_df.groupby(["speaker_id", "transcript_id"])
    valid_synth = synth_grouped.filter(lambda g: set(g["tts_system"]) == set(tts_systems))
    
    # Extract the valid (speaker_id, transcript_id) pairs
    valid_keys = valid_synth[["speaker_id", "transcript_id"]].drop_duplicates()
    
    # Get real entries for only those valid (speaker_id, transcript_id) pairs
    valid_real = pd.merge(real_df, valid_keys, on=["speaker_id", "transcript_id"], how="inner")
    
    # Concatenate real + synthetic to form the fully matched filtered dataset
    final_df = pd.concat([valid_real, valid_synth], ignore_index=True)
    
    
    # === Strategy 1: Speaker-level split ===
    if strategy == "speaker":
        speakers = final_df["speaker_id"].dropna().unique()
        train_spk, test_spk = train_test_split(speakers, test_size=0.2, random_state=random_state)
        train_spk, val_spk = train_test_split(train_spk, test_size=0.1 / 0.8, random_state=random_state)
        
        def assign(speaker_id):
            if speaker_id in test_spk:
                return "test"
            elif speaker_id in val_spk:
                return "val"
            else:
                return "train"
        
        final_df["split"] = final_df["speaker_id"].apply(assign)
    
    
    # === Strategy 2: Utterance-level split ===
    elif strategy == "utterance":
        utt_keys = final_df[["speaker_id", "transcript_id"]].drop_duplicates()
        train_keys, test_keys = train_test_split(utt_keys, test_size=0.2, random_state=random_state)
        train_keys, val_keys = train_test_split(train_keys, test_size=0.1 / 0.8, random_state=random_state)
        
        def assign_utterance_split(row):
            key = (row["speaker_id"], row["transcript_id"])
            if key in set(map(tuple, test_keys.values)):
                return "test"
            elif key in set(map(tuple, val_keys.values)):
                return "val"
            else:
                return "train"
        
        final_df["split"] = final_df.apply(assign_utterance_split, axis=1)
    
    
    # === Strategy 3: Disjoint Speaker + tts_system split ===
    elif strategy == "tts_system":
        
        # Split speakers
        all_speakers = sorted(final_df["speaker_id"].unique())
        train_spk, test_spk = train_test_split(all_speakers, test_size=0.2, random_state=random_state)
        train_spk, val_spk = train_test_split(train_spk, test_size=0.1 / 0.8, random_state=random_state)
        
        def speaker_split(sid):
            if sid in test_spk:
                return 'test'
            elif sid in val_spk:
                return 'val'
            else:
                return 'train'
        
        final_df["speaker_split"] = final_df["speaker_id"].apply(speaker_split)
        
        # Force test TTS system to be 'openvoice' for reproducibility
        test_sys = ['openvoice']
        train_val_sys = [sys for sys in tts_systems if sys not in test_sys]
        
        def tts_split(system):
            if system in test_sys:
                return 'test'
            elif system in train_val_sys:
                return 'train_val'
            else:
                return 'exclude'
        
        final_df["tts_split"] = final_df["tts_system"].apply(
            lambda x: tts_split(x) if x != "original" else "all"
        )
        
        def final_assign(row):
            if row["tts_system"] == "original":
                return row["speaker_split"]
            elif row["tts_split"] == "train_val" and row["speaker_split"] in {"train", "val"}:
                return row["speaker_split"]
            elif row["tts_split"] == "test" and row["speaker_split"] == "test":
                return "test"
            else:
                return None
        
        final_df["split"] = final_df.apply(final_assign, axis=1)
        final_df = final_df.dropna(subset=["split"])
    
    
    # === Return final splits ===
    return {
        'train': final_df[final_df['split'] == 'train'].drop(columns=[col for col in ["speaker_split", "tts_split"] if col in final_df]),
        'val':   final_df[final_df['split'] == 'val'].drop(columns=[col for col in ["speaker_split", "tts_split"] if col in final_df]),
        'test':  final_df[final_df['split'] == 'test'].drop(columns=[col for col in ["speaker_split", "tts_split"] if col in final_df]),
    }


#%%
# === Run splitting for each feature type ===
for split_strategy in SPLIT_STRATEGIES:
    print(f"\n==============================")
    print(f"ğŸ”§ Split strategy: {split_strategy}")
    print(f"==============================")
    
    for feature in FEATURE_TYPES:
        input_path = MANIFEST_DIR / f"unified_{feature}.tsv"
        if not input_path.exists():
            print(f"âš ï¸ Skipping feature '{feature}': file not found at {input_path}\n")
            continue
        
        print(f"ğŸ“‚ Processing feature type: {feature}")
        split_dict = split_manifest(
            manifest_path=input_path,
            strategy=split_strategy,
            random_state=RANDOM_STATE
        )
        
        for name, df in split_dict.items():
            real_count = (df['label'] == 'real').sum()
            synth_count = (df['label'] == 'synthetic').sum()
            print(f"  âœ… {name.capitalize():<6} set â€” total: {len(df):<5} | real: {real_count:<4} | synthetic: {synth_count:<4}")
        
        combined_df = pd.concat(split_dict.values(), ignore_index=True)
        output_path = MANIFEST_DIR / f"split_{split_strategy}_{feature}.tsv"
        combined_df.to_csv(output_path, sep='\t', index=False)
        print(f"  ğŸ’¾ Saved split manifest: {output_path}\n")


#%%
# # Testing
# UNIFIED_MANIFEST_PATH = HERE.parent / "data/manifests/unified_raw.tsv"
# splits = split_manifest(UNIFIED_MANIFEST_PATH, strategy='tts_system')
# splits['val']['tts_system'].value_counts()
# len(splits['val']['speaker_id'].unique())
