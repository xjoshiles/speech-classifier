"""
Synthesize VCTK utterances using the Coqui VITS model for each speaker identity.

Purpose:
    This script ensures that every real speaker in the VCTK corpus has at least N (default: 20)
    of their utterances synthesized using **every** VITS speaker identity. This uniform coverage
    is required for accurate real-to-synthetic speaker matching later on.

    It is designed to address a known issue where the Coqui VITS model misaligned real and synthetic
    speaker identities during training:
        https://github.com/coqui-ai/TTS/issues/2258

How it works:
    - Loads a pre-trained Coqui VITS model (`tts_models/en/vctk/vits`).
    - Iterates over real VCTK speakers and synthesizes their first N utterances using each
      available synthetic speaker in the model.
    - Saves the generated `.wav` files in a structured output directory.

Required Inputs:
    - `vctk-transcript-ids.tsv`: A mapping of utterance IDs to their corresponding transcript texts.
      (Generated by `generate_vctk_transcript_ids.py`)
    - Preprocessed VCTK real audio files in `data/processed/real/vctk-corpus-wav16/raw/`

Output:
    - Synthetic `.wav` files stored in `data/temp/synth/vctk-vits/raw/{vits_speaker}/{utt_id}.wav`

Required Preprocessing:
    - Run the following **before** this script:
        1. `vctk_fix_transcript_case.py`
        2. `vctk_fix_transcript_whitespace.py`
        3. `generate_vctk_transcript_ids.py`

Next Steps:
    - After this script, run `vctk_resample.py` if not already done so, and then
      `vctk_match_vits_speakers.py` to match real and synthetic speaker IDs based on the generated audio.

Configuration:
    - You can customize:
        - Number of utterances per speaker (`NUM_UTTERANCES_PER_SPEAKER`)
        - Whether to overwrite existing `.wav` files (`OVERWRITE`)
        - Output sample rate (`TARGET_SR`)

This script is included for reproducibility and can be safely re-run with `OVERWRITE=True`.
"""

from pathlib import Path
import pandas as pd
from TTS.api import TTS
from utils import process_wav_array

# === Configuration ===
HERE = Path(__file__).parent

# Input paths
VCTK_AUDIO_DIR = HERE.parent / "data/processed/real/vctk-corpus-wav16/raw"
TRANSCRIPT_IDS = HERE.parent / "data/vctk-transcript-ids.tsv"

# Output folder for generated speech
SYNTH_DIR = HERE.parent / "data/temp/synth/vctk-vits/raw"
SYNTH_DIR.mkdir(parents=True, exist_ok=True)

# Processing settings
MODEL_NAME = 'tts_models/en/vctk/vits'
TARGET_SR                  = 16000
NUM_UTTERANCES_PER_SPEAKER = 20
OVERWRITE                  = False  # Set to True to resynthesize

# === Load transcript to ID mappings ===
transcripts = pd.read_csv(TRANSCRIPT_IDS, sep="\t", dtype={"transcript_id": str})
transcripts = dict(zip(transcripts["transcript_id"], transcripts["transcript"]))

# === Initialise chosen Coqui TTS model ===
tts = TTS(model_name=MODEL_NAME, progress_bar=False, gpu=True)

# Native sample rate from model config
native_sr = tts.synthesizer.tts_config.audio["sample_rate"]

#%%
# === MAIN LOOP ===
for speaker_dir in sorted(VCTK_AUDIO_DIR.iterdir()):
    if not speaker_dir.is_dir():
        continue
    
    real_speaker_id = speaker_dir.name
    print(f"\nProcessing speaker {real_speaker_id}...")
    
    audio_files = sorted(speaker_dir.glob("*.wav"))
    
    for audio_file in audio_files[:NUM_UTTERANCES_PER_SPEAKER]:
        utt_id = audio_file.stem
        text   = transcripts.get(utt_id)
        
        for speaker in tts.speakers:
            synth_speaker_tag = speaker.strip()
            
            out_path = SYNTH_DIR / synth_speaker_tag / f"{utt_id}.wav"
            if out_path.exists() and not OVERWRITE:
                continue
            
            out_path.parent.mkdir(parents=True, exist_ok=True)
            
            try:
                wav = tts.tts(text=text, speaker=speaker)
                process_wav_array(wav, native_sr, out_path, TARGET_SR)
                print(f"✓ [{real_speaker_id}] → {synth_speaker_tag}/{utt_id}.wav")
            except Exception as e:
                print(f"✗ Error for {synth_speaker_tag}/{utt_id}: {e}")

print("\nDone synthesizing synthetic audio.")
